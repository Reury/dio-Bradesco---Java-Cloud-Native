{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Demonstra√ß√£o de Ingest√£o de Dados\\n\",\n",
    "    \"\\n\",\n",
    "    \"Este notebook demonstra como ingerir documentos no Azure Blob Storage para posterior indexa√ß√£o no Azure Cognitive Search.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Objetivos\\n\",\n",
    "    \"- Configurar o ambiente de ingest√£o\\n\",\n",
    "    \"- Processar documentos locais\\n\",\n",
    "    \"- Fazer upload para Azure Blob Storage\\n\",\n",
    "    \"- Analisar resultados da ingest√£o\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Imports e configura√ß√µes\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"from src.ingestion.data_ingestion import DocumentIngestion\\n\",\n",
    "    \"from src.ingestion.document_processor import DocumentProcessor\\n\",\n",
    "    \"from src.utils.helpers import setup_logging, get_file_metadata\\n\",\n",
    "    \"from config.azure_config import config\\n\",\n",
    "    \"\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from tqdm.notebook import tqdm\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Setup logging\\n\",\n",
    "    \"setup_logging(\\\"INFO\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Ambiente configurado com sucesso!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Verifica√ß√£o da Configura√ß√£o\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Verificar configura√ß√µes\\n\",\n",
    "    \"config_validation = config.validate_config()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Status da Configura√ß√£o:\\\")\\n\",\n",
    "    \"for key, is_valid in config_validation.items():\\n\",\n",
    "    \"    status = \\\"‚úÖ\\\" if is_valid else \\\"‚ùå\\\"\\n\",\n",
    "    \"    print(f\\\"{status} {key}: {'Configurado' if is_valid else 'N√£o configurado'}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not all(config_validation.values()):\\n\",\n",
    "    \"    print(\\\"\\\\n‚ö†Ô∏è Configure as vari√°veis de ambiente no arquivo .env antes de continuar\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"\\\\n‚úÖ Todas as configura√ß√µes est√£o v√°lidas!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Prepara√ß√£o dos Dados\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Verificar documentos dispon√≠veis\\n\",\n",
    "    \"data_dir = \\\"../data/raw\\\"\\n\",\n",
    "    \"sample_files = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"if os.path.exists(data_dir):\\n\",\n",
    "    \"    for file in os.listdir(data_dir):\\n\",\n",
    "    \"        file_path = os.path.join(data_dir, file)\\n\",\n",
    "    \"        if os.path.isfile(file_path):\\n\",\n",
    "    \"            metadata = get_file_metadata(file_path)\\n\",\n",
    "    \"            sample_files.append(metadata)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if sample_files:\\n\",\n",
    "    \"    df_files = pd.DataFrame(sample_files)\\n\",\n",
    "    \"    print(f\\\"Encontrados {len(sample_files)} arquivos para processamento:\\\")\\n\",\n",
    "    \"    print(df_files[['filename', 'file_type', 'file_size', 'mime_type']].head(10))\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Nenhum arquivo encontrado em ../data/raw/\\\")\\n\",\n",
    "    \"    print(\\\"Adicione alguns documentos de exemplo nesta pasta para continuar.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Processamento de Documentos\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Inicializar processador de documentos\\n\",\n",
    "    \"if config.form_recognizer_endpoint and config.form_recognizer_key:\\n\",\n",
    "    \"    processor = DocumentProcessor(\\n\",\n",
    "    \"        config.form_recognizer_endpoint,\\n\",\n",
    "    \"        config.form_recognizer_key\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Processar alguns documentos de exemplo\\n\",\n",
    "    \"    processed_docs = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for file_info in sample_files[:3]:  # Processar apenas os primeiros 3\\n\",\n",
    "    \"        file_path = os.path.join(data_dir, file_info['filename'])\\n\",\n",
    "    \"        print(f\\\"Processando: {file_info['filename']}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        result = processor.process_document(file_path)\\n\",\n",
    "    \"        processed_docs.append(result)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if result.get('success'):\\n\",\n",
    "    \"            content_preview = result.get('content', '')[:200] + \\\"...\\\"\\n\",\n",
    "    \"            print(f\\\"‚úÖ Sucesso! Preview: {content_preview}\\\")\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(f\\\"‚ùå Erro: {result.get('error')}\\\")\\n\",\n",
    "    \"        print(\\\"-\\\" * 50)\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Form Recognizer n√£o configurado. Pulando processamento avan√ßado.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Ingest√£o para Azure Blob Storage\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Inicializar sistema de ingest√£o\\n\",\n",
    "    \"ingestion = DocumentIngestion(\\n\",\n",
    "    \"    storage_connection_string=config.storage_connection_string,\\n\",\n",
    "    \"    container_name=config.storage_container_name\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Sistema de ingest√£o inicializado para container: {config.storage_container_name}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Fazer upload dos documentos\\n\",\n",
    "    \"if sample_files:\\n\",\n",
    "    \"    print(\\\"Iniciando upload dos documentos...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    results = []\\n\",\n",
    "    \"    for file_info in tqdm(sample_files, desc=\\\"Uploading files\\\"):\\n\",\n",
    "    \"        file_path = os.path.join(data_dir, file_info['filename'])\\n\",\n",
    "    \"        result = ingestion.upload_document(file_path)\\n\",\n",
    "    \"        results.append(result)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Analisar resultados\\n\",\n",
    "    \"    stats = ingestion.get_ingestion_stats(results)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nüìä Estat√≠sticas da Ingest√£o:\\\")\\n\",\n",
    "    \"    print(f\\\"Total de arquivos: {stats['total_files']}\\\")\\n\",\n",
    "    \"    print(f\\\"Sucessos: {stats['successful']} ({stats['success_rate']:.1f}%)\\\")\\n\",\n",
    "    \"    print(f\\\"Falhas: {stats['failed']}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Exibir erros se houver\\n\",\n",
    "    \"    failed_results = [r for r in results if not r['success']]\\n\",\n",
    "    \"    if failed_results:\\n\",\n",
    "    \"        print(\\\"\\\\n‚ùå Arquivos com falha:\\\")\\n\",\n",
    "    \"        for result in failed_results:\\n\",\n",
    "    \"            print(f\\\"- {result['file_path']}: {result['error']}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Nenhum arquivo para processar.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. An√°lise dos Resultados\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Criar visualiza√ß√µes dos resultados\\n\",\n",
    "    \"if sample_files and results:\\n\",\n",
    "    \"    # Distribui√ß√£o por tipo de arquivo\\n\",\n",
    "    \"    file_types = [f['file_type'] for f in sample_files]\\n\",\n",
    "    \"    type_counts = pd.Series(file_types).value_counts()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Gr√°fico 1: Tipos de arquivo\\n\",\n",
    "    \"    type_counts.plot(kind='bar', ax=ax1, color='skyblue')\\n\",\n",
    "    \"    ax1.set_title('Distribui√ß√£o por Tipo de Arquivo')\\n\",\n",
    "    \"    ax1.set_ylabel('Quantidade')\\n\",\n",
    "    \"    ax1.tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Gr√°fico 2: Status dos uploads\\n\",\n",
    "    \"    success_counts = pd.Series([r['success'] for r in results]).value_counts()\\n\",\n",
    "    \"    success_labels = ['Sucesso' if k else 'Falha' for k in success_counts.index]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    ax2.pie(success_counts.values, labels=success_labels, autopct='%1.1f%%', \\n\",\n",
    "    \"            colors=['lightgreen', 'lightcoral'])\\n\",\n",
    "    \"    ax2.set_title('Status dos Uploads')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Tabela de resumo\\n\",\n",
    "    \"    summary_data = []\\n\",\n",
    "    \"    for i, (file_info, result) in enumerate(zip(sample_files, results)):\\n\",\n",
    "    \"        summary_data.append({\\n\",\n",
    "    \"            'Arquivo': file_info['filename'],\\n\",\n",
    "    \"            'Tipo': file_info['file_type'],\\n\",\n",
    "    \"            'Tamanho (KB)': round(file_info['file_size'] / 1024, 1),\\n\",\n",
    "    \"            'Status': '‚úÖ Sucesso' if result['success'] else '‚ùå Falha',\\n\",\n",
    "    \"            'URL': result.get('url', 'N/A')[:50] + '...' if result.get('url') else 'N/A'\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    df_summary = pd.DataFrame(summary_data)\\n\",\n",
    "    \"    print(\\\"\\\\nüìã Resumo Detalhado:\\\")\\n\",\n",
    "    \"    print(df_summary.to_string(index=False))\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"N√£o h√° dados suficientes para gerar visualiza√ß√µes.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Pr√≥ximos Passos\\n\",\n",
    "    \"\\n\",\n",
    "    \"Com os documentos ingeridos no Azure Blob Storage, voc√™ pode agora:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Criar √≠ndices** usando o notebook `02_index_creation_tutorial.ipynb`\\n\",\n",
    "    \"2. **Configurar skills cognitivas** para enriquecimento autom√°tico\\n\",\n",
    "    \"3. **Indexar os documentos** para torn√°-los pesquis√°veis\\n\",\n",
    "    \"4. **Realizar consultas** usando o notebook `03_search_exploration.ipynb`\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Comandos √∫teis para verificar o storage:\\n\",\n",
    "    \"\\n\",\n",
    "    \"```python\\n\",\n",
    "    \"# Listar blobs no container\\n\",\n",
    "    \"from azure.storage.blob import BlobServiceClient\\n\",\n",
    "    \"\\n\",\n",
    "    \"blob_service = BlobServiceClient.from_connection_string(config.storage_connection_string)\\n\",\n",
    "    \"container_client = blob_service.get_container_client(config.storage_container_name)\\n\",\n",
    "    \"\\n\",\n",
    "    \"blobs = list(container_client.list_blobs())\\n\",\n",
    "    \"print(f\\\"Total de blobs no container: {len(blobs)}\\\")\\n\",\n",
    "    \"for blob in blobs[:5]:  # Mostrar os primeiros 5\\n\",\n",
    "    \"    print(f\\\"- {blob.name} ({blob.size} bytes)\\\")\\n\",\n",
    "    \"```\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Salvar resultados para uso posterior\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"\\n\",\n",
    "    \"if results:\\n\",\n",
    "    \"    output_file = \\\"../data/processed/ingestion_results.json\\\"\\n\",\n",
    "    \"    os.makedirs(\\\"../data/processed\\\", exist_ok=True)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    with open(output_file, 'w') as f:\\n\",\n",
    "    \"        json.dump({\\n\",\n",
    "    \"            'timestamp': pd.Timestamp.now().isoformat(),\\n\",\n",
    "    \"            'statistics': stats,\\n\",\n",
    "    \"            'results': results\\n\",\n",
    "    \"        }, f, indent=2, default=str)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"‚úÖ Resultados salvos em: {output_file}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Nenhum resultado para salvar.\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
