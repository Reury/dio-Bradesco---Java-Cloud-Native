{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f13368",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Explora√ß√£o de Pesquisa Inteligente\\n\",\n",
    "    \"\\n\",\n",
    "    \"Este notebook demonstra como realizar pesquisas avan√ßadas e an√°lises nos documentos indexados.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Objetivos\\n\",\n",
    "    \"- Executar diferentes tipos de pesquisa\\n\",\n",
    "    \"- Analisar e visualizar resultados\\n\",\n",
    "    \"- Explorar capacidades de facetas e filtros\\n\",\n",
    "    \"- Gerar insights a partir dos dados\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Imports e configura√ß√µes\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"from src.search.search_engine import IntelligentSearch\\n\",\n",
    "    \"from src.search.query_builder import QueryBuilder\\n\",\n",
    "    \"from src.search.result_processor import SearchResultProcessor\\n\",\n",
    "    \"from config.azure_config import config\\n\",\n",
    "    \"\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import plotly.express as px\\n\",\n",
    "    \"import plotly.graph_objects as go\\n\",\n",
    "    \"from plotly.subplots import make_subplots\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"from datetime import datetime, timedelta\\n\",\n",
    "    \"from collections import Counter\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Configurar estilo dos gr√°ficos\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Ambiente configurado com sucesso!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Configura√ß√£o da Engine de Busca\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Carregar configura√ß√£o do √≠ndice\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    with open('../data/processed/index_configuration.json', 'r') as f:\\n\",\n",
    "    \"        index_config = json.load(f)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    index_name = index_config['index_name']\\n\",\n",
    "    \"    print(f\\\"‚úÖ Configura√ß√£o carregada - √çndice: {index_name}\\\")\\n\",\n",
    "    \"    print(f\\\"   Criado em: {index_config['timestamp']}\\\")\\n\",\n",
    "    \"    print(f\\\"   Campos: {index_config['schema_fields']}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"except FileNotFoundError:\\n\",\n",
    "    \"    print(\\\"‚ö†Ô∏è Arquivo de configura√ß√£o n√£o encontrado. Usando configura√ß√£o padr√£o.\\\")\\n\",\n",
    "    \"    index_name = \\\"intelligent-documents-index\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Inicializar search engine\\n\",\n",
    "    \"search_engine = IntelligentSearch(\\n\",\n",
    "    \"    service_name=config.search_service_name,\\n\",\n",
    "    \"    query_key=config.search_query_key or config.search_admin_key,\\n\",\n",
    "    \"    index_name=index_name\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"result_processor = SearchResultProcessor()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüîç Search engine inicializado para √≠ndice: {index_name}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Explora√ß√£o Inicial dos Dados\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Busca geral para obter overview dos dados\\n\",\n",
    "    \"overview_results = search_engine.advanced_search(\\n\",\n",
    "    \"    query=\\\"*\\\",\\n\",\n",
    "    \"    facets=[\\\"category\\\", \\\"file_type\\\", \\\"language\\\", \\\"sentiment\\\"],\\n\",\n",
    "    \"    top=100\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if overview_results['success']:\\n\",\n",
    "    \"    total_docs = overview_results['total_count']\\n\",\n",
    "    \"    retrieved_docs = len(overview_results['documents'])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"üìä Overview do √çndice:\\\")\\n\",\n",
    "    \"    print(f\\\"   Total de documentos: {total_docs:,}\\\")\\n\",\n",
    "    \"    print(f\\\"   Documentos recuperados para an√°lise: {retrieved_docs}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Processar resultados\\n\",\n",
    "    \"    processed_results = result_processor.process_results(overview_results)\\n\",\n",
    "    \"    analytics = processed_results.get('analytics', {})\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if analytics:\\n\",\n",
    "    \"        print(f\\\"\\\\nüìà Analytics Iniciais:\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Distribui√ß√£o por categoria\\n\",\n",
    "    \"        categories = analytics.get('category_distribution', {})\\n\",\n",
    "    \"        if categories:\\n\",\n",
    "    \"            print(f\\\"   Categorias encontradas: {len(categories)}\\\")\\n\",\n",
    "    \"            for cat, count in list(categories.items())[:5]:\\n\",\n",
    "    \"                print(f\\\"     - {cat}: {count} documentos\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Distribui√ß√£o por idioma\\n\",\n",
    "    \"        languages = analytics.get('language_distribution', {})\\n\",\n",
    "    \"        if languages:\\n\",\n",
    "    \"            print(f\\\"   Idiomas detectados: {list(languages.keys())}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Estat√≠sticas de conte√∫do\\n\",\n",
    "    \"        content_stats = analytics.get('content_statistics', {})\\n\",\n",
    "    \"        if content_stats:\\n\",\n",
    "    \"            file_types = content_stats.get('file_type_distribution', {})\\n\",\n",
    "    \"            print(f\\\"   Tipos de arquivo: {list(file_types.keys())}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(f\\\"‚ùå Erro na busca inicial: {overview_results.get('error')}\\\")\\n\",\n",
    "    \"    total_docs = 0\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Visualiza√ß√µes dos Dados\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"if overview_results['success'] and analytics:\\n\",\n",
    "    \"    # Criar subplots\\n\",\n",
    "    \"    fig = make_subplots(\\n\",\n",
    "    \"        rows=2, cols=2,\\n\",\n",
    "    \"        subplot_titles=('Distribui√ß√£o por Categoria', 'Tipos de Arquivo', \\n\",\n",
    "    \"                       'Distribui√ß√£o por Idioma', 'An√°lise de Sentimento'),\\n\",\n",
    "    \"        specs=[[{\\\"type\\\": \\\"pie\\\"}, {\\\"type\\\": \\\"bar\\\"}],\\n\",\n",
    "    \"               [{\\\"type\\\": \\\"pie\\\"}, {\\\"type\\\": \\\"bar\\\"}]]\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Gr√°fico 1: Categorias\\n\",\n",
    "    \"    categories = analytics.get('category_distribution', {})\\n\",\n",
    "    \"    if categories:\\n\",\n",
    "    \"        fig.add_trace(\\n\",\n",
    "    \"            go.Pie(labels=list(categories.keys()), \\n\",\n",
    "    \"                   values=list(categories.values()),\\n\",\n",
    "    \"                   name=\\\"Categorias\\\"),\\n\",\n",
    "    \"            row=1, col=1\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Gr√°fico 2: Tipos de arquivo\\n\",\n",
    "    \"    content_stats = analytics.get('content_statistics', {})\\n\",\n",
    "    \"    file_types = content_stats.get('file_type_distribution', {})\\n\",\n",
    "    \"    if file_types:\\n\",\n",
    "    \"        fig.add_trace(\\n\",\n",
    "    \"            go.Bar(x=list(file_types.keys()), \\n\",\n",
    "    \"                   y=list(file_types.values()),\\n\",\n",
    "    \"                   name=\\\"Tipos de Arquivo\\\"),\\n\",\n",
    "    \"            row=1, col=2\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Gr√°fico 3: Idiomas\\n\",\n",
    "    \"    languages = analytics.get('language_distribution', {})\\n\",\n",
    "    \"    if languages:\\n\",\n",
    "    \"        fig.add_trace(\\n\",\n",
    "    \"            go.Pie(labels=list(languages.keys()), \\n\",\n",
    "    \"                   values=list(languages.values()),\\n\",\n",
    "    \"                   name=\\\"Idiomas\\\"),\\n\",\n",
    "    \"            row=2, col=1\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Gr√°fico 4: Sentimentos (se dispon√≠vel)\\n\",\n",
    "    \"    # Fazer uma busca espec√≠fica para sentimentos\\n\",\n",
    "    \"    sentiment_results = search_engine.advanced_search(\\n\",\n",
    "    \"        query=\\\"*\\\",\\n\",\n",
    "    \"        facets=[\\\"sentiment\\\"],\\n\",\n",
    "    \"        top=0  # S√≥ queremos as facetas\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if sentiment_results['success'] and sentiment_results.get('facets', {}).get('sentiment'):\\n\",\n",
    "    \"        sentiment_data = sentiment_results['facets']['sentiment']\\n\",\n",
    "    \"        sentiment_labels = [item['value'] for item in sentiment_data]\\n\",\n",
    "    \"        sentiment_counts = [item['count'] for item in sentiment_data]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        fig.add_trace(\\n\",\n",
    "    \"            go.Bar(x=sentiment_labels, \\n\",\n",
    "    \"                   y=sentiment_counts,\\n\",\n",
    "    \"                   name=\\\"Sentimentos\\\"),\\n\",\n",
    "    \"            row=2, col=2\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Atualizar layout\\n\",\n",
    "    \"    fig.update_layout(\\n\",\n",
    "    \"        height=800,\\n\",\n",
    "    \"        title_text=\\\"Dashboard de An√°lise de Documentos\\\",\\n\",\n",
    "    \"        showlegend=False\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    fig.show()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Dados insuficientes para gerar visualiza√ß√µes.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Pesquisas Espec√≠ficas por Dom√≠nio\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Definir consultas de teste por dom√≠nio\\n\",\n",
    "    \"domain_queries = {\\n\",\n",
    "    \"    \\\"Tecnologia\\\": [\\n\",\n",
    "    \"        \\\"intelig√™ncia artificial\\\",\\n\",\n",
    "    \"        \\\"machine learning\\\",\\n\",\n",
    "    \"        \\\"cloud computing\\\",\\n\",\n",
    "    \"        \\\"blockchain\\\",\\n\",\n",
    "    \"        \\\"DevOps\\\"\\n\",\n",
    "    \"    ],\\n\",\n",
    "    \"    \\\"Neg√≥cios\\\": [\\n\",\n",
    "    \"        \\\"estrat√©gia empresarial\\\",\\n\",\n",
    "    \"        \\\"marketing digital\\\",\\n\",\n",
    "    \"        \\\"gest√£o de projetos\\\",\\n\",\n",
    "    \"        \\\"inova√ß√£o\\\",\\n\",\n",
    "    \"        \\\"transforma√ß√£o digital\\\"\\n\",\n",
    "    \"    ],\\n\",\n",
    "    \"    \\\"Jur√≠dico\\\": [\\n\",\n",
    "    \"        \\\"contratos\\\",\\n\",\n",
    "    \"        \\\"compliance\\\",\\n\",\n",
    "    \"        \\\"regulamenta√ß√£o\\\",\\n\",\n",
    "    \"        \\\"LGPD\\\",\\n\",\n",
    "    \"        \\\"direitos autorais\\\"\\n\",\n",
    "    \"    ]\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Executar pesquisas e coletar resultados\\n\",\n",
    "    \"domain_results = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"for domain, queries in domain_queries.items():\\n\",\n",
    "    \"    print(f\\\"\\\\nüîç Testando consultas para dom√≠nio: {domain}\\\")\\n\",\n",
    "    \"    domain_data = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for query in queries:\\n\",\n",
    "    \"        result = search_engine.simple_search(query, top=20)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if result['success']:\\n\",\n",
    "    \"            count = result['total_count']\\n\",\n",
    "    \"            print(f\\\"   '{query}': {count} resultados\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            domain_data.append({\\n\",\n",
    "    \"                'query': query,\\n\",\n",
    "    \"                'count': count,\\n\",\n",
    "    \"                'documents': result['documents']\\n\",\n",
    "    \"            })\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(f\\\"   '{query}': Erro na busca\\\")\\n\",\n",
    "    \"            domain_data.append({\\n\",\n",
    "    \"                'query': query,\\n\",\n",
    "    \"                'count': 0,\\n\",\n",
    "    \"                'documents': []\\n\",\n",
    "    \"            })\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    domain_results[domain] = domain_data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualizar resultados por dom√≠nio\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 3, figsize=(18, 6))\\n\",\n",
    "    \"fig.suptitle('N√∫mero de Documentos por Consulta em Diferentes Dom√≠nios', fontsize=16)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for idx, (domain, data) in enumerate(domain_results.items()):\\n\",\n",
    "    \"    queries = [item['query'] for item in data]\\n\",\n",
    "    \"    counts = [item['count'] for item in data]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    axes[idx].bar(range(len(queries)), counts, color=plt.cm.Set3(idx))\\n\",\n",
    "    \"    axes[idx].set_title(f'Dom√≠nio: {domain}')\\n\",\n",
    "    \"    axes[idx].set_xlabel('Consultas')\\n\",\n",
    "    \"    axes[idx].set_ylabel('N√∫mero de Documentos')\\n\",\n",
    "    \"    axes[idx].set_xticks(range(len(queries)))\\n\",\n",
    "    \"    axes[idx].set_xticklabels(queries, rotation=45, ha='right')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Adicionar valores nos barras\\n\",\n",
    "    \"    for i, count in enumerate(counts):\\n\",\n",
    "    \"        axes[idx].text(i, count + max(counts) * 0.01, str(count), \\n\",\n",
    "    \"                      ha='center', va='bottom')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Estat√≠sticas resumidas\\n\",\n",
    "    \"print(\\\"\\\\nüìä Resumo por Dom√≠nio:\\\")\\n\",\n",
    "    \"for domain, data in domain_results.items():\\n\",\n",
    "    \"    total_docs = sum(item['count'] for item in data)\\n\",\n",
    "    \"    avg_docs = total_docs / len(data) if data else 0\\n\",\n",
    "    \"    best_query = max(data, key=lambda x: x['count']) if data else None\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\n{domain}:\\\")\\n\",\n",
    "    \"    print(f\\\"   Total de documentos encontrados: {total_docs}\\\")\\n\",\n",
    "    \"    print(f\\\"   M√©dia por consulta: {avg_docs:.1f}\\\")\\n\",\n",
    "    \"    if best_query:\\n\",\n",
    "    \"        print(f\\\"   Melhor consulta: '{best_query['query']}' ({best_query['count']} docs)\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. An√°lise de Frases-chave e Entidades\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Buscar documentos com frases-chave e entidades\\n\",\n",
    "    \"enriched_search = search_engine.advanced_search(\\n\",\n",
    "    \"    query=\\\"*\\\",\\n\",\n",
    "    \"    top=50\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if enriched_search['success']:\\n\",\n",
    "    \"    documents = enriched_search['documents']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Extrair todas as frases-chave\\n\",\n",
    "    \"    all_key_phrases = []\\n\",\n",
    "    \"    all_entities = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for doc in documents:\\n\",\n",
    "    \"        # Frases-chave\\n\",\n",
    "    \"        key_phrases = doc.get('key_phrases', [])\\n\",\n",
    "    \"        if isinstance(key_phrases, list):\\n\",\n",
    "    \"            all_key_phrases.extend(key_phrases)\\n\",\n",
    "    \"        elif key_phrases:  # String √∫nica\\n\",\n",
    "    \"            all_key_phrases.append(key_phrases)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Entidades\\n\",\n",
    "    \"        entities = doc.get('entities', [])\\n\",\n",
    "    \"        if isinstance(entities, list):\\n\",\n",
    "    \"            all_entities.extend(entities)\\n\",\n",
    "    \"        elif entities:  # String √∫nica\\n\",\n",
    "    \"            all_entities.append(entities)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Contar frequ√™ncias\\n\",\n",
    "    \"    phrase_counter = Counter(all_key_phrases)\\n\",\n",
    "    \"    entity_counter = Counter(all_entities)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Top 20 frases-chave\\n\",\n",
    "    \"    top_phrases = phrase_counter.most_common(20)\\n\",\n",
    "    \"    # Top 20 entidades\\n\",\n",
    "    \"    top_entities = entity_counter.most_common(20)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nüî§ An√°lise de Frases-chave e Entidades:\\\")\\n\",\n",
    "    \"    print(f\\\"   Total de frases-chave √∫nicas: {len(phrase_counter)}\\\")\\n\",\n",
    "    \"    print(f\\\"   Total de entidades √∫nicas: {len(entity_counter)}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if top_phrases:\\n\",\n",
    "    \"        print(f\\\"\\\\nüìù Top 10 Frases-chave:\\\")\\n\",\n",
    "    \"        for phrase, count in top_phrases[:10]:\\n\",\n",
    "    \"            print(f\\\"   {count:3d}x - {phrase}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if top_entities:\\n\",\n",
    "    \"        print(f\\\"\\\\nüè∑Ô∏è Top 10 Entidades:\\\")\\n\",\n",
    "    \"        for entity, count in top_entities[:10]:\\n\",\n",
    "    \"            print(f\\\"   {count:3d}x - {entity}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"‚ùå Erro ao buscar documentos enriquecidos\\\")\\n\",\n",
    "    \"    top_phrases = []\\n\",\n",
    "    \"    top_entities = []\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualizar frases-chave e entidades mais frequentes\\n\",\n",
    "    \"if top_phrases or top_entities:\\n\",\n",
    "    \"    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Gr√°fico de frases-chave\\n\",\n",
    "    \"    if top_phrases:\\n\",\n",
    "    \"        phrases, phrase_counts = zip(*top_phrases[:15])\\n\",\n",
    "    \"        y_pos = np.arange(len(phrases))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        bars1 = ax1.barh(y_pos, phrase_counts, color='skyblue')\\n\",\n",
    "    \"        ax1.set_yticks(y_pos)\\n\",\n",
    "    \"        ax1.set_yticklabels(phrases)\\n\",\n",
    "    \"        ax1.set_xlabel('Frequ√™ncia')\\n\",\n",
    "    \"        ax1.set_title('Top 15 Frases-chave Mais Frequentes')\\n\",\n",
    "    \"        ax1.invert_yaxis()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Adicionar valores nas barras\\n\",\n",
    "    \"        for i, bar in enumerate(bars1):\\n\",\n",
    "    \"            width = bar.get_width()\\n\",\n",
    "    \"            ax1.text(width, bar.get_y() + bar.get_height()/2, \\n\",\n",
    "    \"                    f'{int(width)}', ha='left', va='center')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Gr√°fico de entidades\\n\",\n",
    "    \"    if top_entities:\\n\",\n",
    "    \"        entities, entity_counts = zip(*top_entities[:15])\\n\",\n",
    "    \"        y_pos = np.arange(len(entities))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        bars2 = ax2.barh(y_pos, entity_counts, color='lightcoral')\\n\",\n",
    "    \"        ax2.set_yticks(y_pos)\\n\",\n",
    "    \"        ax2.set_yticklabels(entities)\\n\",\n",
    "    \"        ax2.set_xlabel('Frequ√™ncia')\\n\",\n",
    "    \"        ax2.set_title('Top 15 Entidades Mais Frequentes')\\n\",\n",
    "    \"        ax2.invert_yaxis()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Adicionar valores nas barras\\n\",\n",
    "    \"        for i, bar in enumerate(bars2):\\n\",\n",
    "    \"            width = bar.get_width()\\n\",\n",
    "    \"            ax2.text(width, bar.get_y() + bar.get_height()/2, \\n\",\n",
    "    \"                    f'{int(width)}', ha='left', va='center')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Dados insuficientes para visualiza√ß√£o de frases-chave e entidades.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Pesquisas Complexas com Query Builder\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Exemplos de consultas complexas\\n\",\n",
    "    \"print(\\\"üîß Testando Query Builder para consultas complexas...\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Consulta 1: Documentos de tecnologia com sentimento positivo\\n\",\n",
    "    \"query_builder = QueryBuilder()\\n\",\n",
    "    \"tech_positive = query_builder.add_term(\\\"tecnologia OR intelig√™ncia artificial\\\") \\\\\\n\",\n",
    "    \"                             .add_filter(\\\"sentiment\\\", \\\"eq\\\", \\\"positive\\\") \\\\\\n\",\n",
    "    \"                             .add_facet(\\\"category\\\") \\\\\\n\",\n",
    "    \"                             .add_sort(\\\"modified_date\\\", \\\"desc\\\") \\\\\\n\",\n",
    "    \"                             .build_search_params()\\n\",\n",
    "    \"\\n\",\n",
    "    \"result1 = search_engine.advanced_search(**tech_positive, top=10)\\n\",\n",
    "    \"print(f\\\"Consulta 1 - Documentos de tecnologia com sentimento positivo:\\\")\\n\",\n",
    "    \"print(f\\\"   Resultados: {result1['total_count'] if result1['success'] else 'Erro'}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Consulta 2: Documentos grandes (>1MB) dos √∫ltimos 6 meses\\n\",\n",
    "    \"six_months_ago = (datetime.now() - timedelta(days=180)).isoformat()\\n\",\n",
    "    \"query_builder.reset()\\n\",\n",
    "    \"large_recent = query_builder.add_term(\\\"*\\\") \\\\\\n\",\n",
    "    \"                           .add_filter(\\\"file_size\\\", \\\"gt\\\", 1048576) \\\\\\n\",\n",
    "    \"                           .add_filter(\\\"modified_date\\\", \\\"gt\\\", six_months_ago) \\\\\\n\",\n",
    "    \"                           .add_facet(\\\"file_type\\\") \\\\\\n\",\n",
    "    \"                           .add_sort(\\\"file_size\\\", \\\"desc\\\") \\\\\\n\",\n",
    "    \"                           .build_search_params()\\n\",\n",
    "    \"\\n\",\n",
    "    \"result2 = search_engine.advanced_search(**large_recent, top=10)\\n\",\n",
    "    \"print(f\\\"\\\\nConsulta 2 - Documentos grandes (>1MB) dos √∫ltimos 6 meses:\\\")\\n\",\n",
    "    \"print(f\\\"   Resultados: {result2['total_count'] if result2['success'] else 'Erro'}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Consulta 3: Busca por frase exata com filtros m√∫ltiplos\\n\",\n",
    "    \"query_builder.reset()\\n\",\n",
    "    \"exact_phrase = query_builder.add_phrase(\\\"machine learning\\\") \\\\\\n\",\n",
    "    \"                           .add_filter(\\\"language\\\", \\\"eq\\\", \\\"pt\\\") \\\\\\n\",\n",
    "    \"                           .add_filter(\\\"file_type\\\", \\\"in\\\", [\\\"pdf\\\", \\\"docx\\\"]) \\\\\\n\",\n",
    "    \"                           .add_facet(\\\"category\\\") \\\\\\n\",\n",
    "    \"                           .add_highlight(\\\"content\\\") \\\\\\n\",\n",
    "    \"                           .build_search_params()\\n\",\n",
    "    \"\\n\",\n",
    "    \"result3 = search_engine.advanced_search(**exact_phrase, top=10)\\n\",\n",
    "    \"print(f\\\"\\\\nConsulta 3 - Frase exata 'machine learning' em portugu√™s (PDF/DOCX):\\\")\\n\",\n",
    "    \"print(f\\\"   Resultados: {result3['total_count'] if result3['success'] else 'Erro'}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Exibir alguns resultados detalhados\\n\",\n",
    "    \"if result1['success'] and result1['documents']:\\n\",\n",
    "    \"    print(f\\\"\\\\nüìÑ Exemplo de resultado da Consulta 1:\\\")\\n\",\n",
    "    \"    doc = result1['documents'][0]\\n\",\n",
    "    \"    print(f\\\"   T√≠tulo: {doc.get('title', 'N/A')[:60]}...\\\")\\n\",\n",
    "    \"    print(f\\\"   Sentimento: {doc.get('sentiment', 'N/A')}\\\")\\n\",\n",
    "    \"    print(f\\\"   Categoria: {doc.get('category', 'N/A')}\\\")\\n\",\n",
    "    \"    print(f\\\"   Score: {doc.get('@search.score', 'N/A')}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. An√°lise de Performance das Consultas\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Teste de performance com diferentes tipos de consulta\\n\",\n",
    "    \"import time\\n\",\n",
    "    \"\\n\",\n",
    "    \"performance_tests = {\\n\",\n",
    "    \"    \\\"Busca simples\\\": lambda: search_engine.simple_search(\\\"tecnologia\\\", top=20),\\n\",\n",
    "    \"    \\\"Busca com filtros\\\": lambda: search_engine.advanced_search(\\n\",\n",
    "    \"        query=\\\"intelig√™ncia artificial\\\",\\n\",\n",
    "    \"        filters=\\\"category eq 'tecnologia'\\\",\\n\",\n",
    "    \"        top=20\\n\",\n",
    "    \"    ),\\n\",\n",
    "    \"    \\\"Busca com facetas\\\": lambda: search_engine.advanced_search(\\n\",\n",
    "    \"        query=\\\"*\\\",\\n\",\n",
    "    \"        facets=[\\\"category\\\", \\\"file_type\\\", \\\"language\\\"],\\n\",\n",
    "    \"        top=20\\n\",\n",
    "    \"    ),\\n\",\n",
    "    \"    \\\"Busca complexa\\\": lambda: search_engine.advanced_search(\\n\",\n",
    "    \"        query='\\\"machine learning\\\" OR \\\"artificial intelligence\\\"',\\n\",\n",
    "    \"        filters=\\\"file_size gt 100000 and language eq 'pt'\\\",\\n\",\n",
    "    \"        facets=[\\\"category\\\", \\\"sentiment\\\"],\\n\",\n",
    "    \"        order_by=[\\\"@search.score desc\\\", \\\"modified_date desc\\\"],\\n\",\n",
    "    \"        top=20\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"performance_results = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚è±Ô∏è Testando performance das consultas...\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"for test_name, test_func in performance_tests.items():\\n\",\n",
    "    \"    times = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Executar 5 vezes cada teste\\n\",\n",
    "    \"    for i in range(5):\\n\",\n",
    "    \"        start_time = time.time()\\n\",\n",
    "    \"        result = test_func()\\n\",\n",
    "    \"        end_time = time.time()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if result.get('success'):\\n\",\n",
    "    \"            times.append(end_time - start_time)\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(f\\\"   ‚ùå Erro em {test_name}: {result.get('error')}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if times:\\n\",\n",
    "    \"        avg_time = np.mean(times)\\n\",\n",
    "    \"        min_time = np.min(times)\\n\",\n",
    "    \"        max_time = np.max(times)\\n\",\n",
    "    \"        std_time = np.std(times)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        performance_results.append({\\n\",\n",
    "    \"            'test': test_name,\\n\",\n",
    "    \"            'avg_time': avg_time,\\n\",\n",
    "    \"            'min_time': min_time,\\n\",\n",
    "    \"            'max_time': max_time,\\n\",\n",
    "    \"            'std_time': std_time,\\n\",\n",
    "    \"            'result_count': result.get('total_count', 0)\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"{test_name}:\\\")\\n\",\n",
    "    \"        print(f\\\"   Tempo m√©dio: {avg_time*1000:.1f}ms\\\")\\n\",\n",
    "    \"        print(f\\\"   Min/Max: {min_time*1000:.1f}ms / {max_time*1000:.1f}ms\\\")\\n\",\n",
    "    \"        print(f\\\"   Resultados: {result.get('total_count', 0)}\\\")\\n\",\n",
    "    \"        print()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualizar performance\\n\",\n",
    "    \"if performance_results:\\n\",\n",
    "    \"    df_perf = pd.DataFrame(performance_results)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Gr√°fico de tempo de resposta\\n\",\n",
    "    \"    bars = ax1.bar(df_perf['test'], df_perf['avg_time'] * 1000, \\n\",\n",
    "    \"                   yerr=df_perf['std_time'] * 1000, capsize=5)\\n\",\n",
    "    \"    ax1.set_title('Tempo M√©dio de Resposta por Tipo de Consulta')\\n\",\n",
    "    \"    ax1.set_ylabel('Tempo (ms)')\\n\",\n",
    "    \"    ax1.set_xticklabels(df_perf['test'], rotation=45, ha='right')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Adicionar valores nas barras\\n\",\n",
    "    \"    for bar, time_val in zip(bars, df_perf['avg_time'] * 1000):\\n\",\n",
    "    \"        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\\n\",\n",
    "    \"                f'{time_val:.1f}ms', ha='center', va='bottom')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Gr√°fico de n√∫mero de resultados\\n\",\n",
    "    \"    ax2.bar(df_perf['test'], df_perf['result_count'], color='lightgreen')\\n\",\n",
    "    \"    ax2.set_title('N√∫mero de Resultados por Tipo de Consulta')\\n\",\n",
    "    \"    ax2.set_ylabel('N√∫mero de Resultados')\\n\",\n",
    "    \"    ax2.set_xticklabels(df_perf['test'], rotation=45, ha='right')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\nüìä Resumo de Performance:\\\")\\n\",\n",
    "    \"    fastest = df_perf.loc[df_perf['avg_time'].idxmin()]\\n\",\n",
    "    \"    slowest = df_perf.loc[df_perf['avg_time'].idxmax()]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"   Consulta mais r√°pida: {fastest['test']} ({fastest['avg_time']*1000:.1f}ms)\\\")\\n\",\n",
    "    \"    print(f\\\"   Consulta mais lenta: {slowest['test']} ({slowest['avg_time']*1000:.1f}ms)\\\")\\n\",\n",
    "    \"    print(f\\\"   Tempo m√©dio geral: {df_perf['avg_time'].mean()*1000:.1f}ms\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Insights e Recomenda√ß√µes\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Gerar insights finais\\n\",\n",
    "    \"insights = {\\n\",\n",
    "    \"    'total_documents': total_docs,\\n\",\n",
    "    \"    'analysis_timestamp': datetime.now().isoformat(),\\n\",\n",
    "    \"    'domain_analysis': {},\\n\",\n",
    "    \"    'content_insights': {},\\n\",\n",
    "    \"    'performance_insights': {},\\n\",\n",
    "    \"    'recommendations': []\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Insights de dom√≠nio\\n\",\n",
    "    \"for domain, data in domain_results.items():\\n\",\n",
    "    \"    total_docs_domain = sum(item['count'] for item in data)\\n\",\n",
    "    \"    insights['domain_analysis'][domain] = {\\n\",\n",
    "    \"        'total_documents': total_docs_domain,\\n\",\n",
    "    \"        'coverage_percentage': (total_docs_domain / total_docs * 100) if total_docs > 0 else 0,\\n\",\n",
    "    \"        'top_query': max(data, key=lambda x: x['count'])['query'] if data else None\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Insights de conte√∫do\\n\",\n",
    "    \"if analytics:\\n\",\n",
    "    \"    insights['content_insights'] = {\\n\",\n",
    "    \"        'unique_categories': len(analytics.get('category_distribution', {})),\\n\",\n",
    "    \"        'languages_detected': len(analytics.get('language_distribution', {})),\\n\",\n",
    "    \"        'file_types': len(analytics.get('content_statistics', {}).get('file_type_distribution', {})),\\n\",\n",
    "    \"        'top_category': max(analytics.get('category_distribution', {}).items(), \\n\",\n",
    "    \"                           key=lambda x: x[1])[0] if analytics.get('category_distribution') else None\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Insights de performance\\n\",\n",
    "    \"if performance_results:\\n\",\n",
    "    \"    avg_response_time = np.mean([r['avg_time'] for r in performance_results])\\n\",\n",
    "    \"    insights['performance_insights'] = {\\n\",\n",
    "    \"        'average_response_time_ms': avg_response_time * 1000,\\n\",\n",
    "    \"        'fastest_query_type': min(performance_results, key=lambda x: x['avg_time'])['test'],\\n\",\n",
    "    \"        'response_time_variance': np.var([r['avg_time'] for r in performance_results]) * 1000\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Gerar recomenda√ß√µes\\n\",\n",
    "    \"recommendations = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"if total_docs < 100:\\n\",\n",
    "    \"    recommendations.append(\\\"Considere adicionar mais documentos para melhorar a qualidade das an√°lises\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if performance_results:\\n\",\n",
    "    \"    avg_time = np.mean([r['avg_time'] for r in performance_results])\\n\",\n",
    "    \"    if avg_time > 1.0:  # Mais de 1 segundo\\n\",\n",
    "    \"        recommendations.append(\\\"Performance das consultas pode ser melhorada com otimiza√ß√£o de √≠ndices\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    simple_time = next((r['avg_time'] for r in performance_results if r['test'] == 'Busca simples'), None)\\n\",\n",
    "    \"    complex_time = next((r['avg_time'] for r in performance_results if r['test'] == 'Busca complexa'), None)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if simple_time and complex_time and complex_time > simple_time * 3:\\n\",\n",
    "    \"        recommendations.append(\\\"Consultas complexas est√£o significativamente mais lentas - considere otimiza√ß√£o\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if analytics:\\n\",\n",
    "    \"    languages = analytics.get('language_distribution', {})\\n\",\n",
    "    \"    if len(languages) > 3:\\n\",\n",
    "    \"        recommendations.append(\\\"M√∫ltiplos idiomas detectados - considere configurar analisadores espec√≠ficos por idioma\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    categories = analytics.get('category_distribution', {})\\n\",\n",
    "    \"    if len(categories) > 10:\\n\",\n",
    "    \"        recommendations.append(\\\"Muitas categorias detectadas - considere consolida√ß√£o ou hierarquia de categorias\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if top_phrases:\\n\",\n",
    "    \"    top_phrase_freq = top_phrases[0][1] if top_phrases else 0\\n\",\n",
    "    \"    if top_phrase_freq > total_docs * 0.5:  # Mais de 50% dos documentos\\n\",\n",
    "    \"        recommendations.append(\\\"Algumas frases-chave s√£o muito comuns - considere ajustar filtros de extra√ß√£o\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"insights['recommendations'] = recommendations\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Exibir insights finais\\n\",\n",
    "    \"print(\\\"\\\\nüéØ INSIGHTS E RECOMENDA√á√ïES FINAIS\\\\n\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüìä Resumo Geral:\\\")\\n\",\n",
    "    \"print(f\\\"   Total de documentos analisados: {total_docs:,}\\\")\\n\",\n",
    "    \"print(f\\\"   Categorias identificadas: {insights['content_insights'].get('unique_categories', 'N/A')}\\\")\\n\",\n",
    "    \"print(f\\\"   Idiomas detectados: {insights['content_insights'].get('languages_detected', 'N/A')}\\\")\\n\",\n",
    "    \"print(f\\\"   Tipos de arquivo: {insights['content_insights'].get('file_types', 'N/A')}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüèÜ Performance:\\\")\\n\",\n",
    "    \"if insights['performance_insights']:\\n\",\n",
    "    \"    perf = insights['performance_insights']\\n\",\n",
    "    \"    print(f\\\"   Tempo m√©dio de resposta: {perf['average_response_time_ms']:.1f}ms\\\")\\n\",\n",
    "    \"    print(f\\\"   Tipo de consulta mais r√°pida: {perf['fastest_query_type']}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüìà Cobertura por Dom√≠nio:\\\")\\n\",\n",
    "    \"for domain, data in insights['domain_analysis'].items():\\n\",\n",
    "    \"    print(f\\\"   {domain}: {data['total_documents']} docs ({data['coverage_percentage']:.1f}% do total)\\\")\\n\",\n",
    "    \"    if data['top_query']:\\n\",\n",
    "    \"        print(f\\\"      Melhor consulta: '{data['top_query']}'\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüí° Recomenda√ß√µes:\\\")\\n\",\n",
    "    \"if recommendations:\\n\",\n",
    "    \"    for i, rec in enumerate(recommendations, 1):\\n\",\n",
    "    \"        print(f\\\"   {i}. {rec}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"   ‚úÖ Sistema est√° funcionando adequadamente!\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\" * 50)\\n\",\n",
    "    \"print(\\\"An√°lise conclu√≠da! üéâ\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Exporta√ß√£o dos Resultados\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Salvar insights e resultados\\n\",\n",
    "    \"os.makedirs('../data/processed', exist_ok=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Salvar insights completos\\n\",\n",
    "    \"with open('../data/processed/search_insights.json', 'w') as f:\\n\",\n",
    "    \"    json.dump(insights, f, indent=2, default=str)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚úÖ Insights salvos em: ../data/processed/search_insights.json\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Exportar dados de performance\\n\",\n",
    "    \"if performance_results:\\n\",\n",
    "    \"    df_perf = pd.DataFrame(performance_results)\\n\",\n",
    "    \"    df_perf.to_csv('../data/processed/performance_analysis.csv', index=False)\\n\",\n",
    "    \"    print(\\\"‚úÖ Dados de performance salvos em: ../data/processed/performance_analysis.csv\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Exportar an√°lise de dom√≠nios\\n\",\n",
    "    \"domain_summary = []\\n\",\n",
    "    \"for domain, data in domain_results.items():\\n\",\n",
    "    \"    for item in data:\\n\",\n",
    "    \"        domain_summary.append({\\n\",\n",
    "    \"            'domain': domain,\\n\",\n",
    "    \"            'query': item['query'],\\n\",\n",
    "    \"            'document_count': item['count']\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"\\n\",\n",
    "    \"if domain_summary:\\n\",\n",
    "    \"    df_domains = pd.DataFrame(domain_summary)\\n\",\n",
    "    \"    df_domains.to_csv('../data/processed/domain_analysis.csv', index=False)\\n\",\n",
    "    \"    print(\\\"‚úÖ An√°lise de dom√≠nios salva em: ../data/processed/domain_analysis.csv\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Exportar frases-chave e entidades\\n\",\n",
    "    \"if top_phrases:\\n\",\n",
    "    \"    df_phrases = pd.DataFrame(top_phrases, columns=['phrase', 'frequency'])\\n\",\n",
    "    \"    df_phrases.to_csv('../data/processed/top_keyphrases.csv', index=False)\\n\",\n",
    "    \"    print(\\\"‚úÖ Frases-chave salvas em: ../data/processed/top_keyphrases.csv\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if top_entities:\\n\",\n",
    "    \"    df_entities = pd.DataFrame(top_entities, columns=['entity', 'frequency'])\\n\",\n",
    "    \"    df_entities.to_csv('../data/processed/top_entities.csv', index=False)\\n\",\n",
    "    \"    print(\\\"‚úÖ Entidades salvas em: ../data/processed/top_entities.csv\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüìÅ Todos os resultados foram salvos na pasta: ../data/processed/\\\")\\n\",\n",
    "    \"print(f\\\"   Timestamp da an√°lise: {insights['analysis_timestamp']}\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
